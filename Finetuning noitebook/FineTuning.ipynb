{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"12W26CDpP9l77VGPLBZj4GIedG5MfURwr","authorship_tag":"ABX9TyPF1JiUEWSvjr9yYc5ocHPz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"0FOuiIW--dO5","executionInfo":{"status":"error","timestamp":1733264243254,"user_tz":300,"elapsed":29585,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"790a001b-6141-46a4-844c-88003e5c9e10"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'data/hymenoptera_data/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-16f9eed5cf68>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/hymenoptera_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0m\u001b[1;32m     33\u001b[0m                                           data_transforms[x])\n\u001b[1;32m     34\u001b[0m                   for x in ['train', 'val']}\n","\u001b[0;32m<ipython-input-1-16f9eed5cf68>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/hymenoptera_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0m\u001b[1;32m     33\u001b[0m                                           data_transforms[x])\n\u001b[1;32m     34\u001b[0m                   for x in ['train', 'val']}\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/hymenoptera_data/train'"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","mean = np.array([0.5, 0.5, 0.5])\n","std = np.array([0.25, 0.25, 0.25])\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","}\n","\n","data_dir = 'data/hymenoptera_data'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=True, num_workers=0)\n","              for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(class_names)\n","\n","\n","def imshow(inp, title):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    plt.title(title)\n","    plt.show()\n","\n","\n","\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","\n","                    if phase == 'train':\n","                        optimizer.zero_grad()\n","                        loss.backward()\n","                        optimizer.step()\n","\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","\n","\n","\n","model = models.resnet18(pretrained=True)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 2)\n","\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","\n","\n","step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","\n","model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n","\n","\n","model_conv = torchvision.models.resnet18(pretrained=True)\n","for param in model_conv.parameters():\n","    param.requires_grad = False\n","\n","num_ftrs = model_conv.fc.in_features\n","model_conv.fc = nn.Linear(num_ftrs, 2)\n","\n","model_conv = model_conv.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n","\n","model_conv = train_model(model_conv, criterion, optimizer_conv,\n","                         exp_lr_scheduler, num_epochs=25)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3s2q7xERLuhV","executionInfo":{"status":"ok","timestamp":1733264658293,"user_tz":300,"elapsed":17585,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"4b84c584-46f0-42b2-bf57-b4b4bb05555d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = '/content/drive/My Drive/Datasets/my_file.csv'\n","df = pd.read_csv(file_path)\n","print(df.head())\n"],"metadata":{"id":"wbvuShzioAN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Define paths to your folders\n","train_ants_dir = '/content/drive/MyDrive/hymenoptera_data/train/ants'\n","train_bees_dir = '/content/drive/MyDrive/hymenoptera_data/train/bees'\n","val_ants_dir = '/content/drive/MyDrive/hymenoptera_data/val/ants'\n","val_bees_dir = '/content/drive/MyDrive/hymenoptera_data/val/bees'\n","\n","# Initialize lists to store file paths and labels\n","file_paths = []\n","labels = []\n","dataset_type = []\n","\n","# Helper function to collect file paths and labels\n","def collect_file_paths(folder_path, label, dataset):\n","    for file_name in os.listdir(folder_path):\n","        file_path = os.path.join(folder_path, file_name)\n","        if os.path.isfile(file_path):  # Check if it's a file\n","            file_paths.append(file_path)\n","            labels.append(label)\n","            dataset_type.append(dataset)\n","\n","# Collect file paths for training data\n","collect_file_paths(train_ants_dir, 'ant', 'train')\n","collect_file_paths(train_bees_dir, 'bee', 'train')\n","\n","# Collect file paths for validation data\n","collect_file_paths(val_ants_dir, 'ant', 'val')\n","collect_file_paths(val_bees_dir, 'bee', 'val')\n","\n","# Create the DataFrame\n","df = pd.DataFrame({\n","    'file_path': file_paths,\n","    'label': labels,\n","    'dataset': dataset_type\n","})\n","\n","# Display the DataFrame\n","pd.set_option('display.max_colwidth', None)\n","print(df.head())\n","\n","# Verify the dataset type counts\n","print(df['dataset'].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEtI1bWTp8yW","executionInfo":{"status":"ok","timestamp":1733265469680,"user_tz":300,"elapsed":127,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"db57f877-8be3-4e6a-d146-2b455aef8cc0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                                          file_path  \\\n","0       /content/drive/MyDrive/hymenoptera_data/train/ants/382971067_0bfd33afe0.jpg   \n","1        /content/drive/MyDrive/hymenoptera_data/train/ants/36439863_0bec9f554f.jpg   \n","2                  /content/drive/MyDrive/hymenoptera_data/train/ants/175998972.jpg   \n","3  /content/drive/MyDrive/hymenoptera_data/train/ants/Nepenthes_rafflesiana_ant.jpg   \n","4       /content/drive/MyDrive/hymenoptera_data/train/ants/342438950_a3da61deab.jpg   \n","\n","  label dataset  \n","0   ant   train  \n","1   ant   train  \n","2   ant   train  \n","3   ant   train  \n","4   ant   train  \n","dataset\n","train    245\n","val      153\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["print(df.groupby(['dataset', 'label']).size())\n"],"metadata":{"id":"bORVQwkcrXO3","executionInfo":{"status":"ok","timestamp":1733265555001,"user_tz":300,"elapsed":137,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"0e4bf883-5cde-43c4-b227-a7ac5df8c4b1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset  label\n","train    ant      124\n","         bee      121\n","val      ant       70\n","         bee       83\n","dtype: int64\n"]}]}]}